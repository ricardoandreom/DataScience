{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Football Object Detection with Tactical Map Position Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "import skimage\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import json\n",
    "import yaml\n",
    "import time\n",
    "from scipy.spatial import distance as sci_dist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get tactical map keypoints positions dictionary\n",
    "json_path = \"./pitch map labels position.json\"\n",
    "with open(json_path, 'r') as f:\n",
    "    keypoints_map_pos = json.load(f)\n",
    "\n",
    "# Get football field keypoints numerical to alphabetical mapping\n",
    "yaml_path = \"./config pitch dataset.yaml\"\n",
    "with open(yaml_path, 'r') as file:\n",
    "    classes_names_dic = yaml.safe_load(file)\n",
    "classes_names_dic = classes_names_dic['names']\n",
    "\n",
    "# Get football field keypoints numerical to alphabetical mapping\n",
    "yaml_path = \"./config players dataset.yaml\"\n",
    "with open(yaml_path, 'r') as file:\n",
    "    labels_dic = yaml.safe_load(file)\n",
    "labels_dic = labels_dic['names']\n",
    "\n",
    "# print(\"Known coordinates of each keypoint on the tactical map:\")\n",
    "# display(pd.DataFrame(keypoints_map_pos, index=['x','y']))\n",
    "# print(\"Numerical label of field keypoints (as defined when training the Yolo model):\")\n",
    "# display(pd.Series(classes_names_dic, name='alpha_label').reset_index().rename({\"index\":\"num_label\"}, axis=1).set_index(\"alpha_label\").transpose())\n",
    "# print(\"Numerical label of the player, referee, and ball objects (as defined when training the Yolo model):\")\n",
    "# display(pd.Series(labels_dic, name='alpha_label').reset_index().rename({\"index\":\"num_label\"}, axis=1).set_index(\"alpha_label\").transpose())\n",
    "# print('\\033[1mThe dataframe representation are not used in what follows (original dictionary will be used)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set video path\n",
    "video_path = './test vid.mp4'\n",
    "\n",
    "# Read tactical map image\n",
    "tac_map = cv2.imread('./tactical map.jpg')\n",
    "\n",
    "# Define team colors (based on chosen video)\n",
    "nbr_team_colors = 2\n",
    "colors_dic = {\n",
    "    \"Chelsea\":[(41,71,138), (220,98,88)], # Chelsea colors (Players kit color, GK kit color)\n",
    "    \"Man City\":[(144,200,255), (188,199,3)] # Man City colors (Players kit color, GK kit color)\n",
    "}\n",
    "\n",
    "colors_list = colors_dic[\"Chelsea\"]+colors_dic[\"Man City\"] # Define color list to be used for detected player team prediction\n",
    "color_list_lab = [skimage.color.rgb2lab([i/255 for i in c]) for c in colors_list] # Converting color_list to L*a*b* space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the YOLOv8 players detection model\n",
    "model_players = YOLO(\"./models/Yolo8L Players/weights/best.pt\")\n",
    "\n",
    "# Load the YOLOv8 field keypoints detection model\n",
    "model_keypoints = YOLO(\"./models/Yolo8M Field Keypoints/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 18 players, 1 referee, 1 ball, 402.8ms\n",
      "Speed: 1.8ms preprocess, 402.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 TLC, 1 TL6MC, 1 TL6ML, 1 TL18MC, 1 TL18ML, 1 TLArc, 1 BL18MC, 215.9ms\n",
      "Speed: 1.3ms preprocess, 215.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 players, 1 referee, 1 ball, 414.7ms\n",
      "Speed: 1.5ms preprocess, 414.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 TLC, 1 TL6MC, 1 TL6ML, 1 TL18MC, 1 TL18ML, 1 TLArc, 1 LMC, 1 BL18MC, 214.0ms\n",
      "Speed: 1.3ms preprocess, 214.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 players, 1 referee, 1 ball, 397.1ms\n",
      "Speed: 1.7ms preprocess, 397.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 TLC, 1 TL6MC, 1 TL6ML, 1 TL18MC, 1 TL18ML, 1 TLArc, 1 LMC, 1 BL18MC, 216.3ms\n",
      "Speed: 1.4ms preprocess, 216.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 players, 1 referee, 1 ball, 396.8ms\n",
      "Speed: 1.6ms preprocess, 396.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 TLC, 1 TL6MC, 1 TL6ML, 1 TL18MC, 1 TL18ML, 1 TLArc, 1 LMC, 1 BL18MC, 1 BLArc, 219.3ms\n",
      "Speed: 1.0ms preprocess, 219.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 players, 1 referee, 399.8ms\n",
      "Speed: 1.6ms preprocess, 399.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 TLC, 1 TL6MC, 1 TL6ML, 1 TL18MC, 1 TL18ML, 1 TLArc, 1 LMC, 1 BL18MC, 1 BLArc, 230.0ms\n",
      "Speed: 1.3ms preprocess, 230.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 players, 1 referee, 1 ball, 389.8ms\n",
      "Speed: 2.0ms preprocess, 389.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 TLC, 1 TL6MC, 1 TL6ML, 1 TL18MC, 1 TL18ML, 1 LMC, 1 BL18MC, 1 BLArc, 225.5ms\n",
      "Speed: 1.5ms preprocess, 225.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 players, 1 referee, 1 ball, 393.8ms\n",
      "Speed: 1.5ms preprocess, 393.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 TLC, 1 TR6MC, 1 TL6MC, 1 TR6ML, 1 TL6ML, 1 TL18MC, 1 TL18ML, 1 TLArc, 1 LMC, 1 BL18MC, 1 BLArc, 227.2ms\n",
      "Speed: 1.7ms preprocess, 227.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 players, 1 referee, 1 ball, 398.9ms\n",
      "Speed: 1.6ms preprocess, 398.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 TLC, 1 TL6MC, 1 TR6ML, 1 TL18MC, 1 TL18ML, 1 TRArc, 1 TLArc, 1 LMC, 1 BL18MC, 1 BLArc, 226.2ms\n",
      "Speed: 1.2ms preprocess, 226.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 players, 1 ball, 395.1ms\n",
      "Speed: 1.3ms preprocess, 395.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 TLC, 1 TR6MC, 1 TR6ML, 1 TL18MC, 1 TL18ML, 1 TRArc, 1 TLArc, 1 RMC, 1 LMC, 1 BL18MC, 1 BLArc, 212.1ms\n",
      "Speed: 1.0ms preprocess, 212.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 players, 398.6ms\n",
      "Speed: 1.3ms preprocess, 398.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 TLC, 1 TR6MC, 1 TL6MC, 1 TL6ML, 1 TL18MC, 1 TL18ML, 1 TLArc, 1 RMC, 1 LMC, 1 BL18MC, 1 BLArc, 214.7ms\n",
      "Speed: 1.2ms preprocess, 214.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 players, 1 referee, 391.6ms\n",
      "Speed: 1.1ms preprocess, 391.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 TR6MC, 1 TL6MC, 1 TR6ML, 1 TL6ML, 1 TL18MC, 1 TL18ML, 1 TRArc, 1 TLArc, 1 RMC, 1 LMC, 1 BL18MC, 1 BLArc, 231.4ms\n",
      "Speed: 2.5ms preprocess, 231.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 players, 1 referee, 395.6ms\n",
      "Speed: 1.1ms preprocess, 395.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 TLC, 1 TR6MC, 1 TL6MC, 1 TR6ML, 1 TL18MC, 1 TRArc, 1 TLArc, 1 RMC, 1 LMC, 1 BL18MC, 1 BRArc, 1 BLArc, 234.5ms\n",
      "Speed: 1.4ms preprocess, 234.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 players, 1 referee, 406.0ms\n",
      "Speed: 1.4ms preprocess, 406.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 TLC, 1 TL6MC, 1 TR6ML, 1 TL18MC, 1 TL18ML, 1 TLArc, 1 RMC, 1 LMC, 1 BL18MC, 1 BRArc, 1 BLArc, 235.4ms\n",
      "Speed: 1.4ms preprocess, 235.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 players, 1 referee, 393.9ms\n",
      "Speed: 1.3ms preprocess, 393.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 TL6MC, 1 TR6ML, 1 TL18MC, 1 TL18ML, 1 TRArc, 1 TLArc, 1 RMC, 1 LMC, 1 BL18MC, 1 BRArc, 1 BLArc, 216.3ms\n",
      "Speed: 1.2ms preprocess, 216.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 players, 1 referee, 390.0ms\n",
      "Speed: 1.3ms preprocess, 390.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 TR6MC, 1 TR6ML, 1 TL18MC, 1 TR18ML, 1 TL18ML, 1 TRArc, 1 TLArc, 1 RMC, 1 LMC, 1 BL18MC, 1 BRArc, 1 BLArc, 236.3ms\n",
      "Speed: 1.6ms preprocess, 236.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 players, 1 referee, 394.5ms\n",
      "Speed: 1.2ms preprocess, 394.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 TR6MC, 1 TR6ML, 1 TL18MC, 1 TL18ML, 1 TRArc, 1 TLArc, 1 RMC, 1 LMC, 1 BL18MC, 1 BRArc, 1 BLArc, 214.1ms\n",
      "Speed: 1.3ms preprocess, 214.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 players, 1 referee, 391.8ms\n",
      "Speed: 1.4ms preprocess, 391.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 TR6MC, 1 TR6ML, 1 TL6ML, 1 TL18MC, 1 TL18ML, 1 TRArc, 1 RMC, 1 LMC, 1 BL18MC, 1 BRArc, 1 BLArc, 216.3ms\n",
      "Speed: 1.5ms preprocess, 216.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 players, 1 referee, 405.1ms\n",
      "Speed: 1.8ms preprocess, 405.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 TR6MC, 1 TR6ML, 1 TL6ML, 1 TL18MC, 1 TL18ML, 1 TRArc, 1 RMC, 1 LMC, 1 BL18MC, 1 BRArc, 1 BLArc, 216.9ms\n",
      "Speed: 1.3ms preprocess, 216.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 players, 1 referee, 1 ball, 393.1ms\n",
      "Speed: 1.6ms preprocess, 393.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 TR6MC, 1 TR6ML, 1 TL6ML, 1 TL18MC, 1 TL18ML, 1 TRArc, 1 RMC, 1 LMC, 1 BL18MC, 1 BRArc, 1 BLArc, 230.4ms\n",
      "Speed: 1.6ms preprocess, 230.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 21 players, 1 referee, 417.0ms\n",
      "Speed: 1.6ms preprocess, 417.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 TR6MC, 1 TR6ML, 1 TL18MC, 1 TL18ML, 1 TRArc, 1 RMC, 1 LMC, 1 LML, 1 BL18MC, 1 BRArc, 1 BLArc, 222.7ms\n",
      "Speed: 1.4ms preprocess, 222.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 players, 1 referee, 404.5ms\n",
      "Speed: 1.5ms preprocess, 404.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 TL18MC, 1 TL18ML, 1 TRArc, 1 TLArc, 1 RMC, 1 LMC, 1 LML, 1 BL18MC, 1 BRArc, 1 BLArc, 217.6ms\n",
      "Speed: 1.3ms preprocess, 217.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 players, 1 referee, 1 ball, 421.5ms\n",
      "Speed: 1.4ms preprocess, 421.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 TLC, 1 TR6MC, 1 TR6ML, 1 TL18MC, 1 TL18ML, 1 TRArc, 1 TLArc, 1 RMC, 1 BL18MC, 1 BRArc, 1 BLArc, 232.0ms\n",
      "Speed: 1.2ms preprocess, 232.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 players, 393.3ms\n",
      "Speed: 1.5ms preprocess, 393.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 TLC, 1 TR6MC, 1 TR6ML, 1 TL18MC, 1 TL18ML, 1 TRArc, 1 TLArc, 1 RMC, 1 LMC, 1 LML, 1 BL18MC, 1 BRArc, 1 BLArc, 226.1ms\n",
      "Speed: 1.5ms preprocess, 226.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 players, 1 ball, 391.9ms\n",
      "Speed: 1.5ms preprocess, 391.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 TLC, 1 TR6MC, 1 TR6ML, 1 TL18MC, 1 TL18ML, 1 TRArc, 1 TLArc, 1 RMC, 1 LML, 1 BL18MC, 1 BLArc, 229.4ms\n",
      "Speed: 1.9ms preprocess, 229.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "# Open video file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Initialize frame counter\n",
    "frame_nbr = 0\n",
    "\n",
    "# Set keypoints average displacement tolerance level (in pixels) [set to -1 to always update homography matrix]\n",
    "keypoints_displacement_mean_tol = 10\n",
    "\n",
    "# Set confidence thresholds for players and field keypoints detections\n",
    "player_model_conf_thresh = 0.60\n",
    "keypoints_model_conf_thresh = 0.70\n",
    "\n",
    "# Set variable to record the time when we processed last frame \n",
    "prev_frame_time = 0\n",
    "# Set variable to record the time at which we processed current frame \n",
    "new_frame_time = 0\n",
    "\n",
    "# Store the ball track history\n",
    "ball_track_history = {'src':[],\n",
    "                      'dst':[]\n",
    "}\n",
    "\n",
    "# Count consecutive frames with no ball detected\n",
    "nbr_frames_no_ball = 0\n",
    "# Threshold for number of frames with no ball to reset ball track (frames)\n",
    "nbr_frames_no_ball_thresh = 30\n",
    "# Distance threshold for ball tracking (pixels)\n",
    "ball_track_dist_thresh = 100\n",
    "# Maximum ball track length (detections)\n",
    "max_track_length = 35\n",
    "\n",
    "\n",
    "#posicao da bola\n",
    "bola_x = 0\n",
    "bola_y = 0\n",
    "\n",
    "#indice do jogador que tem a bola\n",
    "jogador_com_bola = False   # nao podemos \"confiar\" no ID do jogador porque varia de frame para frame. 0: ninguem tem a bola, 1: alguem tem a bola\n",
    "equipa_com_bola = \"\"\n",
    "equipa_anterior_com_bola = \"\"\n",
    "ultima_accao = \"\"\n",
    "\n",
    "\n",
    "#Accções possíveis\n",
    "passe = False\n",
    "interceccao = False\n",
    "recepcao = False\n",
    "\n",
    "encontrou_jogador_com_bola = False\n",
    "dist_euclideana = -1\n",
    "\n",
    "min_dist_jogador_bola = 100000000\n",
    "\n",
    "#heuristica X : tentativa de golo: equipa faz um \"passe\" para a regiao da baliza oposta\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#thresholds - Raio da circunferencia de controlo de bola\n",
    "threshold_posse_bola = 25\n",
    "\n",
    "detected_labels_prev = []\n",
    "# Loop through the video frames\n",
    "while cap.isOpened():\n",
    "    \n",
    "    # Update frame counter\n",
    "    frame_nbr += 1\n",
    "\n",
    "    # Read a frame from the video\n",
    "    success, frame = cap.read()\n",
    "\n",
    "\n",
    "    #para lidar com a limitação do computador\n",
    "    if frame_nbr % 5 != 0:\n",
    "        continue\n",
    "\n",
    "    # Reset tactical map image for each new frame\n",
    "    tac_map_copy = tac_map.copy()\n",
    "\n",
    "    # Reset ball tracks\n",
    "    if nbr_frames_no_ball>nbr_frames_no_ball_thresh:\n",
    "            ball_track_history['dst'] = []\n",
    "            ball_track_history['src'] = []\n",
    "\n",
    "    # Process the frame if it was successfuly read\n",
    "    if success:\n",
    "        \n",
    "        #################### Part 1 ####################\n",
    "        # Object Detection & Coordiante Transofrmation #\n",
    "        ################################################\n",
    "\n",
    "        # Run YOLOv8 players inference on the frame\n",
    "        results_players = model_players(frame, conf=player_model_conf_thresh)\n",
    "        # Run YOLOv8 field keypoints inference on the frame\n",
    "        results_keypoints = model_keypoints(frame, conf=keypoints_model_conf_thresh)\n",
    "\n",
    "        ## Extract detections information\n",
    "        bboxes_p = results_players[0].boxes.xyxy.cpu().numpy()                          # Detected players, referees and ball (x,y,x,y) bounding boxes\n",
    "        bboxes_p_c = results_players[0].boxes.xywh.cpu().numpy()                        # Detected players, referees and ball (x,y,w,h) bounding boxes    \n",
    "        labels_p = list(results_players[0].boxes.cls.cpu().numpy())                     # Detected players, referees and ball labels list\n",
    "        confs_p = list(results_players[0].boxes.conf.cpu().numpy())                     # Detected players, referees and ball confidence level\n",
    "        \n",
    "        bboxes_k = results_keypoints[0].boxes.xyxy.cpu().numpy()                        # Detected field keypoints (x,y,w,h) bounding boxes\n",
    "        bboxes_k_c = results_keypoints[0].boxes.xywh.cpu().numpy()                        # Detected field keypoints (x,y,w,h) bounding boxes\n",
    "        labels_k = list(results_keypoints[0].boxes.cls.cpu().numpy())                   # Detected field keypoints labels list\n",
    "\n",
    "        # Convert detected numerical labels to alphabetical labels\n",
    "        detected_labels = [classes_names_dic[i] for i in labels_k]\n",
    "\n",
    "        # Extract detected field keypoints coordiantes on the current frame\n",
    "        detected_labels_src_pts = np.array([list(np.round(bboxes_k_c[i][:2]).astype(int)) for i in range(bboxes_k_c.shape[0])])\n",
    "\n",
    "        # Get the detected field keypoints coordinates on the tactical map\n",
    "        detected_labels_dst_pts = np.array([keypoints_map_pos[i] for i in detected_labels])\n",
    "\n",
    "\n",
    "        ## Calculate Homography transformation matrix when more than 4 keypoints are detected\n",
    "        if len(detected_labels) > 3:\n",
    "            # Always calculate homography matrix on the first frame\n",
    "            if frame_nbr > 1:\n",
    "                # Determine common detected field keypoints between previous and current frames\n",
    "                common_labels = set(detected_labels_prev) & set(detected_labels)\n",
    "                #common_labels = set(detected_labels)\n",
    "                # When at least 4 common keypoints are detected, determine if they are displaced on average beyond a certain tolerance level\n",
    "                if len(common_labels) > 3:\n",
    "                    common_label_idx_prev = [detected_labels_prev.index(i) for i in common_labels]   # Get labels indexes of common detected keypoints from previous frame\n",
    "                    common_label_idx_curr = [detected_labels.index(i) for i in common_labels]        # Get labels indexes of common detected keypoints from current frame\n",
    "                    coor_common_label_prev = detected_labels_src_pts_prev[common_label_idx_prev]     # Get labels coordiantes of common detected keypoints from previous frame\n",
    "                    coor_common_label_curr = detected_labels_src_pts[common_label_idx_curr]          # Get labels coordiantes of common detected keypoints from current frame\n",
    "                    coor_error = mean_squared_error(coor_common_label_prev, coor_common_label_curr)  # Calculate error between previous and current common keypoints coordinates\n",
    "                    update_homography = coor_error > keypoints_displacement_mean_tol                 # Check if error surpassed the predefined tolerance level\n",
    "                else:\n",
    "                    update_homography = True                                                         \n",
    "            else:\n",
    "                update_homography = True\n",
    "\n",
    "            if  update_homography:\n",
    "                h, mask = cv2.findHomography(detected_labels_src_pts,                   # Calculate homography matrix\n",
    "                                              detected_labels_dst_pts)                  \n",
    "            \n",
    "            detected_labels_prev = detected_labels.copy()                               # Save current detected keypoint labels for next frame\n",
    "            detected_labels_src_pts_prev = detected_labels_src_pts.copy()               # Save current detected keypoint coordiantes for next frame\n",
    "\n",
    "            bboxes_p_c_0 = bboxes_p_c[[i==0 for i in labels_p],:]                       # Get bounding boxes information (x,y,w,h) of detected players (label 0)\n",
    "            bboxes_p_c_2 = bboxes_p_c[[i==2 for i in labels_p],:]                       # Get bounding boxes information (x,y,w,h) of detected ball(s) (label 2)\n",
    "\n",
    "            # Get coordinates of detected players on frame (x_cencter, y_center+h/2)\n",
    "            detected_ppos_src_pts = bboxes_p_c_0[:,:2]  + np.array([[0]*bboxes_p_c_0.shape[0], bboxes_p_c_0[:,3]/2]).transpose()\n",
    "            # Get coordinates of the first detected ball (x_center, y_center)\n",
    "            detected_ball_src_pos = bboxes_p_c_2[0,:2] if bboxes_p_c_2.shape[0]>0 else None\n",
    "\n",
    "            # Transform players coordinates from frame plane to tactical map plance using the calculated Homography matrix\n",
    "            pred_dst_pts = []                                                           # Initialize players tactical map coordiantes list\n",
    "            for pt in detected_ppos_src_pts:                                            # Loop over players frame coordiantes\n",
    "                pt = np.append(np.array(pt), np.array([1]), axis=0)                     # Covert to homogeneous coordiantes\n",
    "                dest_point = np.matmul(h, np.transpose(pt))                              # Apply homography transofrmation\n",
    "                dest_point = dest_point/dest_point[2]                                   # Revert to 2D-coordiantes\n",
    "                pred_dst_pts.append(list(np.transpose(dest_point)[:2]))                 # Update players tactical map coordiantes list\n",
    "            pred_dst_pts = np.array(pred_dst_pts)\n",
    "\n",
    "            # Transform ball coordinates from frame plane to tactical map plane using the calculated Homography matrix\n",
    "            if detected_ball_src_pos is not None:\n",
    "                pt = np.append(np.array(detected_ball_src_pos), np.array([1]), axis=0)\n",
    "                dest_point = np.matmul(h, np.transpose(pt))\n",
    "                dest_point = dest_point/dest_point[2]\n",
    "                detected_ball_dst_pos = np.transpose(dest_point)\n",
    "\n",
    "\n",
    "\n",
    "                bola_x = int(detected_ball_dst_pos[0])\n",
    "                bola_y = int(detected_ball_dst_pos[1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # Update track ball position history\n",
    "                if len(ball_track_history['src'])>0 :\n",
    "                    if np.linalg.norm(detected_ball_src_pos-ball_track_history['src'][-1])<ball_track_dist_thresh:\n",
    "                        ball_track_history['src'].append((int(detected_ball_src_pos[0]), int(detected_ball_src_pos[1])))\n",
    "                        ball_track_history['dst'].append((int(detected_ball_dst_pos[0]), int(detected_ball_dst_pos[1])))\n",
    "                    else:\n",
    "                        ball_track_history['src']=[(int(detected_ball_src_pos[0]), int(detected_ball_src_pos[1]))]\n",
    "                        ball_track_history['dst']=[(int(detected_ball_dst_pos[0]), int(detected_ball_dst_pos[1]))]\n",
    "                else:\n",
    "                    ball_track_history['src'].append((int(detected_ball_src_pos[0]), int(detected_ball_src_pos[1])))\n",
    "                    ball_track_history['dst'].append((int(detected_ball_dst_pos[0]), int(detected_ball_dst_pos[1])))\n",
    "            # Remove oldest tracked ball postion if track exceedes threshold        \n",
    "            if len(ball_track_history) > max_track_length:\n",
    "                    ball_track_history['src'].pop(0)\n",
    "                    ball_track_history['dst'].pop(0)\n",
    "\n",
    "        ######### Part 2 ########## \n",
    "        # Players Team Prediction #\n",
    "        ###########################\n",
    "\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)                                      # Convert frame to RGB\n",
    "        obj_palette_list = []                                                                   # Initialize players color palette list\n",
    "        palette_interval = (0,5)                                                                # Color interval to extract from dominant colors palette (1rd to 5th color)\n",
    "        annotated_frame = frame                                                                 # Create annotated frame \n",
    "\n",
    "        encontrou_jogador_com_bola = False\n",
    "        jogador_com_bola = False\n",
    "        min_dist_jogador_bola = 100000000\n",
    "        ## Loop over detected players (label 0) and extract dominant colors palette based on defined interval\n",
    "        for i, j in enumerate(list(results_players[0].boxes.cls.cpu().numpy())):\n",
    "            if int(j) == 0:\n",
    "                bbox = results_players[0].boxes.xyxy.cpu().numpy()[i,:]                         # Get bbox info (x,y,x,y)\n",
    "                obj_img = frame_rgb[int(bbox[1]):int(bbox[3]), int(bbox[0]):int(bbox[2])]       # Crop bbox out of the frame\n",
    "                obj_img_w, obj_img_h = obj_img.shape[1], obj_img.shape[0]\n",
    "                center_filter_x1 = np.max([(obj_img_w//2)-(obj_img_w//5), 1])\n",
    "                center_filter_x2 = (obj_img_w//2)+(obj_img_w//5)\n",
    "                center_filter_y1 = np.max([(obj_img_h//3)-(obj_img_h//5), 1])\n",
    "                center_filter_y2 = (obj_img_h//3)+(obj_img_h//5)\n",
    "                center_filter = obj_img[center_filter_y1:center_filter_y2, \n",
    "                                        center_filter_x1:center_filter_x2]\n",
    "                obj_pil_img = Image.fromarray(np.uint8(center_filter))                          # Convert to pillow image\n",
    "                    \n",
    "                reduced = obj_pil_img.convert(\"P\", palette=Image.Palette.WEB)                   # Convert to web palette (216 colors)\n",
    "                palette = reduced.getpalette()                                                  # Get palette as [r,g,b,r,g,b,...]\n",
    "                palette = [palette[3*n:3*n+3] for n in range(256)]                              # Group 3 by 3 = [[r,g,b],[r,g,b],...]\n",
    "                color_count = [(n, palette[m]) for n,m in reduced.getcolors()]                  # Create list of palette colors with their frequency\n",
    "                RGB_df = pd.DataFrame(color_count, columns = ['cnt', 'RGB']).sort_values(       # Create dataframe based on defined palette interval\n",
    "                                      by = 'cnt', ascending = False).iloc[\n",
    "                                          palette_interval[0]:palette_interval[1],:]\n",
    "                palette = list(RGB_df.RGB)                                                      # Convert palette to list (for faster processing)\n",
    "                annotated_frame = cv2.rectangle(annotated_frame,                                # Add center filter bbox annotations\n",
    "                                                (int(bbox[0])+center_filter_x1, \n",
    "                                                 int(bbox[1])+ center_filter_y1),  \n",
    "                                                (int(bbox[0])+center_filter_x2, \n",
    "                                                 int(bbox[1])+center_filter_y2), (0,0,0), 2)\n",
    "                \n",
    "                # Update detected players color palette list\n",
    "                obj_palette_list.append(palette)\n",
    "        \n",
    "        ## Calculate distances between each color from every detected player color palette and the predefined teams colors\n",
    "        players_distance_features = []\n",
    "        # Loop over detected players extracted color palettes\n",
    "        for palette in obj_palette_list:\n",
    "            palette_distance = []\n",
    "            palette_lab = [skimage.color.rgb2lab([i/255 for i in color]) for color in palette]  # Convert colors to L*a*b* space\n",
    "            # Loop over colors in palette\n",
    "            for color in palette_lab:\n",
    "                distance_list = []\n",
    "                # Loop over predefined list of teams colors\n",
    "                for c in color_list_lab:\n",
    "                    #distance = np.linalg.norm([i/255 - j/255 for i,j in zip(color,c)])\n",
    "                    distance = skimage.color.deltaE_cie76(color, c)                             # Calculate Euclidean distance in Lab color space\n",
    "                    distance_list.append(distance)                                              # Update distance list for current color\n",
    "                palette_distance.append(distance_list)                                          # Update distance list for current palette\n",
    "            players_distance_features.append(palette_distance)                                  # Update distance features list\n",
    "\n",
    "        ## Predict detected players teams based on distance features\n",
    "        players_teams_list = []\n",
    "        # Loop over players distance features\n",
    "        for distance_feats in players_distance_features:\n",
    "            vote_list=[]\n",
    "            # Loop over distances for each color \n",
    "            for dist_list in distance_feats:\n",
    "                team_idx = dist_list.index(min(dist_list))//nbr_team_colors                     # Assign team index for current color based on min distance\n",
    "                vote_list.append(team_idx)                                                      # Update vote voting list with current color team prediction\n",
    "            players_teams_list.append(max(vote_list, key=vote_list.count))                      # Predict current player team by vote counting\n",
    "\n",
    "\n",
    "        #################### Part 3 #####################\n",
    "        # Updated Frame & Tactical Map With Annotations #\n",
    "        #################################################\n",
    "\n",
    "        ball_color_bgr = (0,0,255)                                                                          # Color (GBR) for ball annotation on tactical map\n",
    "        j=0                                                                                                 # Initializing counter of detected players\n",
    "        palette_box_size = 10                                                                               # Set color box size in pixels (for display)\n",
    "        \n",
    "        # Loop over all detected object by players detection model\n",
    "        for i in range(bboxes_p.shape[0]):\n",
    "            conf = confs_p[i]                                                                               # Get confidence of current detected object\n",
    "            if labels_p[i]==0:                                                                              # Display annotation for detected players (label 0)\n",
    "                \n",
    "                # Display extracted color palette for each detected player\n",
    "                palette = obj_palette_list[j]                                                               # Get color palette of the detected player\n",
    "                for k, c in enumerate(palette):\n",
    "                    c_bgr = c[::-1]                                                                         # Convert color to BGR\n",
    "                    annotated_frame = cv2.rectangle(annotated_frame, (int(bboxes_p[i,2])+3,                 # Add color palette annotation on frame\n",
    "                                                            int(bboxes_p[i,1])+k*palette_box_size),\n",
    "                                                            (int(bboxes_p[i,2])+palette_box_size,\n",
    "                                                            int(bboxes_p[i,1])+(palette_box_size)*(k+1)),\n",
    "                                                              c_bgr, -1)\n",
    "\n",
    "                team_name = list(colors_dic.keys())[players_teams_list[j]]                                  # Get detected player team prediction\n",
    "                color_rgb = colors_dic[team_name][0]                                                        # Get detected player team color\n",
    "                color_bgr = color_rgb[::-1]                                                                 # Convert color to bgr\n",
    "\n",
    "                annotated_frame = cv2.rectangle(annotated_frame, (int(bboxes_p[i,0]), int(bboxes_p[i,1])),  # Add bbox annotations with team colors\n",
    "                                                (int(bboxes_p[i,2]), int(bboxes_p[i,3])), color_bgr, 1)\n",
    "                \n",
    "                \n",
    "                \n",
    "                # Add tactical map player postion color coded annotation if more than 3 field keypoints are detected\n",
    "                if len(detected_labels_src_pts)>3:\n",
    "\n",
    "                    jogador_j_x = int(pred_dst_pts[j][0])\n",
    "                    jogador_j_y = int(pred_dst_pts[j][1])\n",
    "\n",
    "                    cv2.putText(annotated_frame, team_name + f\" {j} - {jogador_j_x}, {jogador_j_y}\",                                    # Add team name annotations\n",
    "                             (int(bboxes_p[i,0]), int(bboxes_p[i,1])-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                               color_bgr, 2)\n",
    "\n",
    "\n",
    "                    ##########################################################################################\n",
    "                    #   Lógica para perceber quem tem a bola\n",
    "                    ##########################################################################################\n",
    "\n",
    "                    # se a bola está próxima de um jogador assumimos que esse jogador está a driblar a bola\n",
    "\n",
    "                    dist_euclideana = sci_dist.euclidean( (bola_x, bola_y), (jogador_j_x, jogador_j_y))\n",
    "                    if dist_euclideana < min_dist_jogador_bola:\n",
    "                        min_dist_jogador_bola = dist_euclideana\n",
    "                        equipa_com_bola = team_name\n",
    "\n",
    "\n",
    "                    \n",
    "                    \n",
    "\n",
    "                        \n",
    "                    \n",
    "                    tac_map_copy = cv2.circle(tac_map_copy, (int(pred_dst_pts[j][0]),int(pred_dst_pts[j][1])),\n",
    "                                          radius=5, color=color_bgr, thickness=-1)\n",
    "\n",
    "                j+=1                                                                                        # Update players counter\n",
    "            else:                                                                                           # Display annotation for otehr detections (label 1, 2)\n",
    "                annotated_frame = cv2.rectangle(annotated_frame, (int(bboxes_p[i,0]), int(bboxes_p[i,1])),  # Add white colored bbox annotations\n",
    "                                                 (int(bboxes_p[i,2]), int(bboxes_p[i,3])), (255,255,255), 1)\n",
    "                cv2.putText(annotated_frame, labels_dic[labels_p[i]] + f\" {conf:.2f} - {int(detected_ball_dst_pos[0])},{int(detected_ball_dst_pos[1])}\",                      # Add white colored label text annotations\n",
    "                            (int(bboxes_p[i,0]), int(bboxes_p[i,1])-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                              (255,255,255), 2)\n",
    "\n",
    "                # Add tactical map ball postion annotation if detected\n",
    "                if detected_ball_src_pos is not None:\n",
    "                    tac_map_copy = cv2.circle(tac_map_copy, (int(detected_ball_dst_pos[0]), \n",
    "                                                   int(detected_ball_dst_pos[1])), radius=5, \n",
    "                                                   color=ball_color_bgr, thickness=3)\n",
    "                    \n",
    "\n",
    "        ##########################################################################################\n",
    "        #   Lógica para perceber a acção actual (passe, drible ou intercecção)\n",
    "        ##########################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #Após a verificação por todos os jogadores nesta frame\n",
    "        if  min_dist_jogador_bola < threshold_posse_bola:\n",
    "            \n",
    "            # se ninguem tinha a bola antes e passou e o ultimo jogador que teve a bola é da mesma enquipa, entao é passe\n",
    "            jogador_com_bola = True\n",
    "            passe = False\n",
    "            interceccao = False\n",
    "\n",
    "            #heuristica 3: recepção: se ultima acção foi um passe e a equipa atual é a mesma da anterior \n",
    "            recepcao = equipa_anterior_com_bola == equipa_com_bola\n",
    "        else:\n",
    "            #heuristica 1: passe é quando a mesma equipa mantem a posse de bola  \n",
    "            passe = equipa_com_bola == equipa_anterior_com_bola\n",
    "            #heuristica 2: interceccao é quando a bola passa a ser controlada pela equipa oposta\n",
    "            interceccao = equipa_com_bola != equipa_anterior_com_bola\n",
    "            jogador_com_bola = False\n",
    "\n",
    "            \n",
    "\n",
    "        equipa_anterior_com_bola = equipa_com_bola\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(bboxes_k.shape[0]):\n",
    "            annotated_frame = cv2.rectangle(annotated_frame, (int(bboxes_k[i,0]), int(bboxes_k[i,1])),  # Add bbox annotations with team colors\n",
    "                                        (int(bboxes_k[i,2]), int(bboxes_k[i,3])), (0,0,0), 1)\n",
    "        \n",
    "        # Plot the ball tracks on tactical map\n",
    "        if len(ball_track_history['src'])>0:\n",
    "            points = np.hstack(ball_track_history['dst']).astype(np.int32).reshape((-1, 1, 2))\n",
    "            tac_map_copy = cv2.polylines(tac_map_copy, [points], isClosed=False, color=(0, 0, 100), thickness=2)\n",
    "        \n",
    "        # Combine annotated frame and tactical map in one image with colored border separation\n",
    "        border_color = [255,255,255]                                                                        # Set border color (BGR)\n",
    "        annotated_frame=cv2.copyMakeBorder(annotated_frame, 40, 10, 10, 10,                                 # Add borders to annotated frame\n",
    "                                            cv2.BORDER_CONSTANT, value=border_color)\n",
    "        tac_map_copy = cv2.copyMakeBorder(tac_map_copy, 70, 50, 10, 10, cv2.BORDER_CONSTANT,                # Add borders to tactical map \n",
    "                                           value=border_color)      \n",
    "        tac_map_copy = cv2.resize(tac_map_copy, (tac_map_copy.shape[1], annotated_frame.shape[0]))          # Resize tactical map\n",
    "        final_img = cv2.hconcat((annotated_frame, tac_map_copy))                                            # Concatenate both images\n",
    "        ## Add info annotation\n",
    "        cv2.putText(final_img, f\"Tactical Map {frame_nbr}\", (1370,40), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,0,0), 2)\n",
    "        cv2.putText(final_img, f\"Equipa com bola: {equipa_com_bola}\", (1320,60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,0), 2)\n",
    "        cv2.putText(final_img, f\"Dist: {int(min_dist_jogador_bola)}\", (1320,80), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,0), 2)\n",
    "        #Print da accção atual\n",
    "        cv2.putText(final_img, f\"Passe\" if passe else \"\" , (1430,80), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,0), 2)\n",
    "        cv2.putText(final_img, f\"Interceccao\" if interceccao else \"\" , (1430,80), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,0), 2)\n",
    "        #cv2.putText(final_img, f\"Recepcao\" if recepcao else \"\" , (1430,80), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,0), 2)\n",
    "        cv2.putText(final_img, f\"Drible\" if jogador_com_bola else \"\" , (1530,80), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,0), 2)\n",
    "        #cv2.putText(final_img, \"Jogada: \" + \"passe\" if passe == 1 else \"\", (1320,80), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,0), 2)\n",
    "        cv2.putText(final_img, \"Press 'p' to pause & 'q' to quit\", (820,30), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,0,0), 2)\n",
    "\n",
    "\n",
    "        new_frame_time = time.time()                                                                        # Get time after finished processing current frame\n",
    "        fps = 1/(new_frame_time-prev_frame_time)                                                            # Calculate FPS as 1/(frame proceesing duration)\n",
    "        prev_frame_time = new_frame_time                                                                    # Save current time to be used in next frame\n",
    "        cv2.putText(final_img, \"FPS: \" + str(int(fps)), (20,30), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,0,0), 2)\n",
    "        \n",
    "        # Display the final annotated frame\n",
    "        cv2.imshow(\"YOLOv8 Players and Field Keypoints Detection with Team Prediction and Tactical Map\",    \n",
    "                    final_img)\n",
    "\n",
    "        # Treat keyboard user inputs (\"p\" for pause/unpause & \"q\" for quit)\n",
    "        key = cv2.waitKey(1)\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "        if key == ord('p'):\n",
    "            cv2.waitKey(-1) #wait until any key is pressed\n",
    "    else:\n",
    "        # Break the loop if the end of the video is reached\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close the display window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
